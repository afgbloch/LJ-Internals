%!TEX root = ../../../FYP_Dissertation.tex

The first thing interesting to note is that we can deactivate the JIT engine using
the \emph{-joff} command-line argument of LuaJIT and we can see that the VM is
slightly faster than the worst case scenario with the JIT activated. This can
be explained by the fact that in those cases the actual code is entirely run by
the VM, plus the time spent by the compiler trying to record and generate traces
that are aborted. These claims can be verified by using the \emph{v}
option of the profiler (see Section \ref{Sec:Profiler}). So
why so much time is spent in the VM and why all these traces are
aborted. This is where things gets complicated. When run alone the
performance tests mentioned earlier are always perfectly fine. It depends on
the context, i.e. the code run before, that sometime these
tests take an incredible amount of time. In addition to that, the dump module of
LuaJIT is very useful when we want to study isolated problems, but in this case
where the amount of code run influence the result, this tool generates to much
informations to be useful.\\

We will still present here some insights on this issue with some unsuccessful
tentative of solutions.

The first thing is that in some run the \emph{\_\_index}
function of the object model (presented in previous sections) gets blacklisted
(see Section \ref{Subsec:abort}). After that no hierarchy chaining can be
successfully recorded inside another trace making all of them running
exclusively in the VM. This is due to a mechanism of LuaJIT that we can call
\emph{cascading blacklisting} that consists of blacklisting bytecodes while
recording a trace that hit already blacklisted bytecodes. This is very inconvenient
because it means that a piece of code that can't be properly compiled for
whatever reasons, can lead to very bad performance of the object model for the rest of the run.
This is even more problematic knowing that blacklisting is permanent for
an entire run of LuaJIT.

A second interesting fact to try to explain the observed performance instability
is the hot path detection, which is very lazy and uses the hashed program
counter (see Section \ref{Subsec:hot-path}) generating false positive easily.
So any modifications to the code can change the bytecode alignment and create
potential false positives, changing in its turn the entire profile of the code
generated. This explanation is an educated guess and couldn't be formally proven
to explain the change in the observed behavior after modifying slightly the
codes.

Another thing to consider is that LuaJIT strings are internalized (see
Section \ref{Subsec:string-inter}) and that memory addresses are used has
"identifier" for their comparisons or hash-table slot selections.
Due to the ASLR (Address Space Layout Randomization) of many operating systems,
two consecutive runs of the exact same code will generate different addresses for
internalized strings and possibly different placements inside the hash-tables.
In Lua,
iterating over a hash-table can be done through the \emph{pairs} iterator that
doesn't enforce any special order (it just iterates sequentially over the internal
table structure), thus two runs can result in keys not being read in the same order,
which makes LuaJIT execute the codes in a different order possibly triggering new
false positives and changing the behavior of the JIT.\\

Now let's have a look at few modifications performed on LuaJIT to try
to circumvent the blacklisting problem. The first idea was that blacklisting
should be context specific, so any compiler full traces flush (that we can
internally detect) should walk through the bytecodes and reset the flag of
blacklisted functions or loop-like bytecodes. The second idea was to slightly
change the behavior of this \emph{cascading blacklisting} feature by letting
traces to record over blacklisted bytecodes instead of aborting immediately.
Unfortunately these two tried modifications didn't bring any substantial
improvement over stability or performance. It has to be noted that
blacklisting is still useful and do sometime improves performance as it
prevents the JIT from spending time recording a trace that would end-up to be aborted
anyway. Moreover we have to keep in mind that the VM is very well optimized and
quite fast, making in certain cases the extra work done by the JIT not worth it.
However, this can still be a general nice idea to keep in mind and might be
reintroduced later.
