%!TEX root = ../../../FYP_Dissertation.tex

The first thing interesting to note is that we can deactivate the JIT engine using
the \emph{-joff} command-line argument of LuaJIT and we can see that the VM is
slightly faster than the worst case scenario with the JIT activated. This can
be explained by the fact that in those cases the actual code is entirely run by
the VM, plus the compiler spent some time trying to record and generate traces
that end-up being aborted. Those claim can be verified by using the \emph{v}
option of the profiler (see Section \ref{Sec:Profiler}). The question now is :
why is it, that so much time is spent in the VM and why all those trace gets
aborted. This is where things gets complicated. When run stand-alone the
performance test mentioned earlier are always perfectly fine. It is depending of
the context, meaning the code that has been run before, that sometime makes those
test take a incredible amount of time. In addition of that the dump module of
LuaJIT is very useful when we want to study isolated problems but in this case
where the amount of code run influence the result, this tool generate to much
informations without much help to manipulate them, making it a needle in a
haystack kind of problem.\\

We will still present here some insight on this issue with some unsuccessful
tentative of solutions.

The first thing is that in some run the \emph{\_\_index}
function of the model object (presented in previous sections) gets blacklisted
(see Section \ref{Subsec:abort}). After that no hierarchy chaining can be
successfully recorded inside another trace making all of them running
exclusively in the VM. This is due to a mechanism of LuaJIT that we can call
\emph{cascading blacklisting} that consist of blacklisting bytecode that tries to
record a trace that hit another blacklisted bytecode. This is very inconvenient
because it means that a piece of code that can't be properly compiled for
whatever the reason can make the model object very slow for the rest of the run.
This is even more problematic knowing that blacklisting is permanent for the
lifetime of a particular bytecode, making it in this case for an entire run of
LuaJIT.

A second interesting fact to try to explain the instability part of the problem
is the fact that the hot path detection is very lazy and use the hashed program
counter (see Section \ref{Subsec:hot-path}) making false positive very easy to
occur. So any change to the code can change the bytecode alignment and the
potential false positive, changing in its turn the entire profile of the code
generated. This explanation is an educated guess and couldn't be formally proven
to be explaining in its own the change of behavior seen when slightly modifying
codes.

Another thing to consider is that in LuaJIT strings are internalized (see
Section \ref{Subsec:string-inter}) and that the memory address where they are
stored is used has "identifier" for string comparisons or hash-table placements.
Due to the ASLR (Address Space Layout Randomization) of many operating systems,
two consecutive runs of the exact same code will generate different address for
internalized string and possibly different placement inside hash-tables. In Lua
iterating over a hash-table can be done through the \emph{pairs} iterator that
doesn't enforce any special order (it just iterate sequentially over the internal
table structure), thus two runs can result in keys not being read in the same order,
making the JIT "see" the codes in a different order possibly changing false positive
and other behavior of the JIT.\\

Now let's have a look at a few modifications of LuaJIT that has been done to try
to circumvent the blacklisting problem. The first idea was that blacklisting
should be context specific, so any compiler wide trace flush (that we can
internally detect) should walk through the bytecode resetting the flag to any
blacklisted function or loop-like bytecode. The second idea was to slightly
change the behavior of this \emph{cascading blacklisting} feature by letting
traces record over blacklisted bytecode instead of aborting immediately.
Unfortunately those two tried modifications didn't bring any substantial
improvement over stability or performance. They can still be a general nice idea
to keep in mind and might be reintroduced later.
