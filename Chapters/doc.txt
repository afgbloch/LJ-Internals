================================================================================
Interesting LuaJIT Presentation: https://mrale.ph/talks/vmss16/#/
================================================================================
-JBC
0006 => UGET     2   0      ; find
 - 1st column : bc number
 - 2nd column : branch targets of a function
 - 3rd column : bc instruction
 - other-1... : bc arguments
 - last       : comment corresponding lua code
================================================================================
Recording:
----------
 - Hashed profile counters: Bytecode instructions to trigger the
  start of a hot trace use low-overhead hashed profiling counters.
  The profile is imprecise because collisions are ignored. The
  hash table is kept very small to reduce D-cache impact (only two
  hot cache lines). Since NLF weeds out most false positives, this
  doesn''t deteriorate hot trace detection.

  [Neither using hashed profile counters, nor imprecise profiling,
  nor using profiling to detect hot loops is new. But the specific
  combination may be original.]
- talk about penalty
- natural-loop first (NLF) -> region-selection
- lj_trace.c
  - trace_state : State machine for the trace compiler.
    - LJ_TRACE_START : start recording (call to trace_start).
      change state to LJ_TRACE_RECORD.
    - LJ_TRACE_RECORD : recording in process (looping over "lj_record_ins").
    - LJ_TRACE_END : end of recording + apply pending bytcode patch
      + apply optimizations on IR.
    - LJ_TRACE_ASM : assemble the trace and call trace_stop().
    - LJ_TRACE_ERR : abort (trace_abort).
  - trace_start: does jit_State setup and allocations.
  - trace_stop: patch the bc to use the compiled version instead of the interpreted
    once.
  - trace_abort: does state cleanup, handle Penalize or blacklist.
- lj_record_ins: is a huge switch case on the bc to record a specific bytcode
  instruction and generate the corresponding specialized IR code of the instruction
  before execution. (executed inside a pcall -> _ERR bu throwing lua intarnal exception)
- lj_record_stop
  - trace stitching (call to c using c API)
  - end of the hotloop
  - hit an other already compiled loop (link to it)
  - return statement
    - return to interpretor for unhandled cases
    - when downrec limit reach for side-trace (nagative frame depth)
    - tail-rec is detected (limit reach in the same framedepth)
    - limit reach in up recursion (positive frame depth)
  - hit a compiled function (link to its trace)
- there exist two types of trace
  - parent trace ->
  - side trace (recursive) ?? ->
- hot is detected ->
  - recorde a parent trace
  - change of the J->state to become LJ_TRACE_START
  - start recording the first bytecode (run trace_state until abort _ERR or _END)
- recording is the fact of executing the code while remembering dynamic data/type
  /controlflow decision to generate a specialized version of this code that
- Reason to abort -> see abort.txt
- lj_ffrecord.c: records data for fast function call
- lj_crecord.c: records C data ops
================================================================================
Paragraph on flush policies ??
================================================================================
Optimizations:
--------------
during LJ_TRACE_END state the following optimizations function are called
  - lj_opt_dce: perform dce optimization
  - lj_opt_loop:
  - lj_opt_split:
  - lj_opt_sink:
- dce (dead code elimination) (2)
  - in lj_opt_dce
  - Pre-LOOP only - ASM already performs DCE.
  - performed durring trace end.
  - performed in two phases
    - 1st: called mark snap mark all ir reference in snapshots
    - 2nd: called propagate that iteratively mark operands of maked ir
    and replace non-marked ir by nop isftructions.
- loop optimizations (3) (add a trace dump or images to illustrate this
  - Code hoisting via unrolling and copy-substitution (LOOP):
    Traditional loop-invariant code motion (LICM) is mostly useless
    for the IR resulting from dynamic languages. The IR has many
    guards and most subsequent instructions are control-dependent on
    them. The first non-hoistable guard would effectively prevent
    hoisting of all subsequent instructions.

    The LOOP pass does synthetic unrolling of the recorded IR,
    combining copy-substitution with redundancy elimination to
    achieve code hoisting. The unrolled and copy-substituted
    instructions are simply fed back into the compiler pipeline,
    which allows reuse of all optimizations for redundancy
    elimination. Loop recurrences are detected on-the-fly and a
    minimized set of PHIs is generated.

  -- That's why we use a special form of unrolling using copy-substitution,
  -- combined with redundancy elimination:
  --
  -- The recorded instruction stream is re-emitted to the compiler pipeline
  -- with substituted operands. The substitution table is filled with the
  -- refs returned by re-emitting each instruction. This can be done
  -- on-the-fly, because the IR is in strict SSA form, where every ref is
  -- defined before its use.
  --
  -- This aproach generates two code sections, separated by the LOOP
  -- instruction:
  --
  -- 1. The recorded instructions form a kind of pre-roll for the loop. It
  -- contains a mix of invariant and variant instructions and performs
  -- exactly one loop iteration (but not necessarily the 1st iteration).
  --
  -- 2. The loop body contains only the variant instructions and performs
  -- all remaining loop iterations.

- split optimizations (only for 32bits architecture)
- sink optimizations
- Fold optimizations:(lj_opt_fold.c) (1)
  lj_foldef.h is generated by buildvm_fold.c at compile time (see build lib section).
  rules are declared using the LJFOLD macro they contains the ir opcode and a rule
  on the parametters it applies to.
  lj_opt_fold is the engine (main) function.
  -- Every entry in the generated hash table is a 32 bit pattern:
  --
  -- xxxxxxxx iiiiiii lllllll rrrrrrrrrr
  --
  --   xxxxxxxx = 8 bit index into fold function table
  --    iiiiiii = 7 bit folded instruction opcode
  --    lllllll = 7 bit left instruction opcode
  -- rrrrrrrrrr = 8 bit right instruction opcode or 10 bits from literal field
  lj_opt_fold.c:
    - constant folding
    - algebraic simplifications
    - reassociation
    - common subexpression elimination
    - Array bounds check elimination
  lj_opt_mem.c: Memory access optimizations
    - AA  : Alias Analysis using high-level semantic disambiguation.
    - FWD : Load Forwarding (L2L) + Store Forwarding (S2L).
    - DSE : Dead-Store Elimination.
  lj_opt_narrow.c:
    - narrowing
  - Rule-based FOLD engine: The FOLD engine is primarily used for
    constant folding, algebraic simplifications and reassociation.
    Most traditional compilers have an evolutionary grown set of
    implicit rules, spread over thousands of hand-coded tiny
    conditionals.

    The rule-based FOLD engine uses a declarative approach to
    combine the first and second level of lookup. It allows wildcard
    lookup with masked keys, too. A pre-processor generates a
    semi-perfect hash table for constant-time rule lookup. It''s able
    to deal with thousands of rules in a uniform manner without
    performance degradation. A declarative approach is also much
    easier to maintain.
-  Narrowing optimizations
  - Narrowing of numbers to integers: Predictive narrowing is used
    for induction variables. Demand-driven narrowing is used for
    index expressions using a backpropagation algorithm.

    This avoids the complexity associated with speculative, eager
    narrowing, which also causes excessive control-flow dependencies
    due to the many overflow checks. Selective narrowing is better
    at exploiting the combined bandwidth of the FP and integer units
    of the CPU and avoids clogging up the branch unit.
================================================================================
Assembler:
----------
- lj_asm.c and lj_asm.h
- lj_asm_(target).c spezialized part for each platform (target)
- lj_emit_(target).h:
- lj_asm_trace() is the main function called in the LJ_TRACE_ASM state
  - loop on asm_ir for each ir instruction
- use ASMState
- Assemble a trace in linear backwards order

================================================================================
how can we intern lua table slot in traces.
================================================================================
IR:
----
- SSA (Static single assignment) based (cf : https://www.wikiwand.com/en/Static_single_assignment_form)
- Data-flow for loops is represented using PHI-instructions.
- Control-flow is always implicit.
- operands are 16 bit references
- implemented with a bidirectionally growable array
- Skip-list chains: The IR is threaded with segregated, per-opcode
  skip-list chains. The links are stored in a multi-purpose 16 bit
  field in the instruction. This facilitates low-overhead lookup
  for CSE, DSE and alias analysis. Back-linking enables short-cut
  searches (average overhead is less than 1 lookup). Incremental
  build-up is trivial. No hashes, no sets, no complex updates.
- a single High-level IR across all optimization stage.
- Trace IR code is represented as an array in memory.
- The array includes two different things: instructions and constants.
- Instructions are stored at "upwards" indices 0,1,2,... ( > 0x8000 )
- Constants are stored at "downwards" indices -1,-2,-3,... ( < 0x8000 )
- References to array elements are "biased" by adding 0x8000.
- ir reference are index in the ir array.
- Every instruction has an output data type.
- IR constants are interned and can be compared for equality only by looking at their references.
- Guarded assertions have a dual purpose
  - They provide an assertion about their operands.
  - They are emitted by the backend as branching comparisons,
    - true ->  fall-through path.
    - false ->  outcome exits the trace and restores the state using last snapshot.

-- IR instruction format (64 bit).
--
--    16      16     8   8   8   8
-- +-------+-------+---+---+---+---+
-- |  op1  |  op2  | t | o | r | s |
-- +-------+-------+---+---+---+---+
-- |  op12/i/gco32 |   ot  | prev  | (alternative fields in union)
-- +-------+-------+---+---+---+---+
-- |  TValue/gco64                 | (2nd IR slot for 64 bit constants)
-- +---------------+-------+-------+
--        32           16      16
--
-- prev is only valid prior to register allocation and then reused for r + s.
--
-- t    : type
-- o    : opcode
-- r    : register allocation
-- s    : spill slot
-- prev : chain of instruction of same opcode
================================================================================
Programming advice:
  1) for i=1,#s do end
  2) for v in ipairs(s) do end
1) is better in terms of performance. (to be confirmed)
                        **************************
Jitting start always jiting the inner loop first
                        **************************
When starting a record hotcount is reseted even if trace endup aborted.
                        **************************
Indexing a table with a string should be as fast as with a reference (table).
================================================================================
- check if vector size can go down -> yes
- check hypothesis of pairs ? -> vector first, hash part second
- check '?' in error messages (table.insert, table.remove, band) (builtin vs functions)
- Where does the limit of 65000 identifier per chunk comes from.
================================================================================
traces can have flow controle ? (if statement ?)
  -> NO only implicitly : guards break the trace and restore the closest snapshot.
================================================================================
- jflush option : does it mean that codes can be keept from a run to the other ?
================================================================================
- make a GCObj never collectable by gc.
- why allocator is global ? -> It is not :)
- does gc goes through the lua stack.
================================================================================
- jit.flush doesn''t remove blacklistings
- function that ends by a c api/ffi tail-call can not be compile in standalone.
  - potential solution is wrapping return value with ().
- lua_setmetatable run flushall mcode because cdata metatamethode lookup is specialise
  metatable is immutable.
- does jit.on remove the blacklist of a given function ? -> yes
- Inject changes after the first test failed:
  - white list only doesn''t work
  - white list + clear penalty cache doesn''t work
  - white list + clear penalty cache + clear hotcount +
    clear J->prngstate doesn''t work
  - white list + flush does cure the problem
  - flush only does cure the problem (normal ???)
- No performance loss if flushall remove blacklisting
================================================================================
  - LJ_PRNG_BITS in lj_jit.h for penalty used for penalty randomization.
================================================================================
LuaJIT Multithreading:
----------------------
GG_State     : Global state, main thread and extra fields are allocated together.
global_State : Global state, shared by all threads of a Lua universe.

(see also lj_state.h, lj_state.c)

lua_open <=> luaL_newstate : create a fully separate LuaJIT with everything separated
  - allocator
  - garbage collector
  - GG_State
  - global_State
  - Jit_state
================================================================================
Loom: Mostly usefull to use hypetext link to navigate between traces
-----
- launch loom programmatically
  local loom = require"ljit_loom"
  local tmpl = loom.template("loom.html")
  loom.on()
  local out  = loom.off(tmpl)
  local file = assert(io.open("report.html", "w"))
  file:write(out)
  file:close()
- launch loom through the command line
  rlwrap ./mad -jloom=,out.html test.lua
NB:
  - flushs make loom crash (tmp fix)
  - MAD.tostring export (in all.mad) makes loom crash
================================================================================
- function call are always inlined into the trace when possible
  - need to be verified ?
  - what are the conditions ?
================================================================================
- Controle flow is strictly linear (no branch inside a trace)
================================================================================
- Use the model object for has a full example
================================================================================
- lookup the same constant keys in hashtables of many different shapes and sizes
is bad !!!!
================================================================================
https://github.com/lukego/blog/issues/28
================================================================================
Advice for Report: (brain dump)
------------------
- keep the detailed ans structured LuaJIT doc in annexe (?)
- say that annex took a lot of time (no documentation existing)
- focus on explaining from context -> through mad
- a big part on luajit (overall, scheamatic of luajit)
- a big part on why mad
- talk about sequence, element, tracking, survey, model object
- talk about instability
- talk about dumps
- talk about the miss of tools
- talk about the miss of predictabilty
- talk about different version of the model object
- tiny talk about madx -> mad-ng
- trace explosion
- talk about performance in matrix ffi.cast and issues with the gc.
- talk about gc64 mode
- talk about permanent blacklisting
- talk about collision in hot detection (run dependent)
- add a section on RaptorJIT
- profiler issues
- gdb
================================================================================
